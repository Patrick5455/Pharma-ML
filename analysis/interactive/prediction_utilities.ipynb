{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#convert .ipynb notes to scripts \n",
    "import notebooktoall as nb\n",
    "\n",
    "# predefined modules\n",
    "# from prediction_utilities import preprocess\n",
    "# from prediction_utilities import preprocess\n",
    "\n",
    "\n",
    "#preprocessing libraries \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_vars(data, show_plot=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    This functions checks for columns with outlers using the IQR method\n",
    "    \n",
    "    It accespts as argmuent a dataset. \n",
    "    show_plot can be set to True to output pairplots of outlier columns\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    outliers = [] \n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    num_data = data.select_dtypes(include='number')\n",
    "    result = dict ((((num_data < (Q1 - 1.5 * IQR)) | (num_data > (Q3 + 1.5 * IQR)))==True).any())\n",
    "    for k,v in result.items():\n",
    "        if v == True: \n",
    "            outliers.append(k)\n",
    "    if show_plot:\n",
    "        pair_plot = sns.pairplot(data[outliers]);\n",
    "        print(f'{result},\\n\\n Visualization of outlier columns')\n",
    "        return pair_plot\n",
    "    else:\n",
    "        return data[outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, to_drop=[]):\n",
    "    \n",
    "    \"\"\"\n",
    "    The preprocess function takes as primary argument the data \n",
    "    and peform the following stepwise transformations to it:\n",
    "    \n",
    "    1. impute missing val\n",
    "    ues of numerical and categorical columns \n",
    "    using median and constant values respectively\n",
    "    \n",
    "    2. scales dataset using the RobustScaler (robust to outlier values present in this dataset)\n",
    "    \n",
    "    3. Encodes categorical values to numerical values\n",
    "    \"\"\"\n",
    "    \n",
    "    columns = data.columns.to_list()\n",
    "    \n",
    "    # split data to numeric vs categorical\n",
    "    numeric_features = data.select_dtypes(include=[\n",
    "        'int64', 'float64']).columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(to_drop) > 0:\n",
    "        data = data.drop(to_drop, axis=1)\n",
    "        categorical_features = data.select_dtypes(include=[\n",
    "        'object']).columns\n",
    "        print(categorical_features) \n",
    "    else: \n",
    "        categorical_features = data.select_dtypes(include=[\n",
    "        'object']).columns\n",
    "        \n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    #('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor) ])\n",
    "    \n",
    "    for col in to_drop:\n",
    "        columns.remove(col) \n",
    "    \n",
    "    trans_data = my_pipeline.fit_transform(data)\n",
    "    \n",
    "    return pd.DataFrame(trans_data, columns=columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_datatype(data, dtype, col_list, date_col_name='Date'):\n",
    "    \"\"\"\n",
    "    This converts specified columns names of a data to the specified data type\n",
    "    It also uses the name od the date column of the dataset to know the data columns\n",
    "    ans convert to datetime object\n",
    "    \"\"\"\n",
    "    for i in col_list:\n",
    "        if i != date_col_name:\n",
    "            data = data.astype({i:dtype})\n",
    "        else:\n",
    "            data[date_col_name] = pd.to_datetime(data.Date)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pharma_project",
   "language": "python",
   "name": "venv_pharma_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
